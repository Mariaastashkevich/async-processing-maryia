"""initial_schema

Revision ID: 64dfff8c929a
Revises: 
Create Date: 2026-01-16 15:39:47.156562

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = '64dfff8c929a'
down_revision: Union[str, Sequence[str], None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('datasets',
    sa.Column('id', sa.Uuid(), nullable=False),
    sa.Column('owner_id', sa.String(length=45), nullable=False),
    sa.Column('name', sa.String(length=255), nullable=False),
    sa.Column('status', sa.Enum('UPLOADED', 'VALIDATING', 'READY', 'FAILED', name='datasetstatus'), nullable=False),
    sa.Column('storage_uri', sa.String(), nullable=False),
    sa.Column('format', sa.String(length=20), nullable=False),
    sa.Column('size_bytes', sa.Integer(), nullable=False),
    sa.Column('created_at', sa.DateTime(), nullable=False),
    sa.Column('updated_at', sa.DateTime(), nullable=False),
    sa.CheckConstraint("format IN ('csv', 'json', 'parquet')", name='ck_datasets_format'),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_datasets_owner_id'), 'datasets', ['owner_id'], unique=False)
    op.create_table('jobs',
    sa.Column('id', sa.Uuid(), nullable=False),
    sa.Column('dataset_id', sa.Uuid(), nullable=False),
    sa.Column('job_type', sa.String(length=20), nullable=False),
    sa.Column('status', sa.Enum('PENDING', 'RUNNING', 'COMPLETED', 'FAILED', 'CANCELED', name='jobstatus'), nullable=False),
    sa.Column('params', sa.JSON(), nullable=False),
    sa.Column('result_uri', sa.String(), nullable=True),
    sa.Column('error_message', sa.String(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=False),
    sa.Column('started_at', sa.DateTime(), nullable=True),
    sa.Column('finished_at', sa.DateTime(), nullable=True),
    sa.CheckConstraint("job_type IN ('metrics', 'normalize', 'anomalies')", name='ck_jobs_job_type'),
    sa.ForeignKeyConstraint(['dataset_id'], ['datasets.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_jobs_dataset_id'), 'jobs', ['dataset_id'], unique=False)
    op.create_table('job_events',
    sa.Column('id', sa.Uuid(), nullable=False),
    sa.Column('job_id', sa.Uuid(), nullable=False),
    sa.Column('event_type', sa.Enum('CREATED', 'STARTED', 'PROCESSING', 'FINISHED', 'FAILED', name='eventtype'), nullable=False),
    sa.Column('payload', sa.JSON(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=False),
    sa.ForeignKeyConstraint(['job_id'], ['jobs.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index('ix_job_events_job_id_created_at', 'job_events', ['job_id', 'created_at'], unique=False)
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index('ix_job_events_job_id_created_at', table_name='job_events')
    op.drop_table('job_events')
    op.drop_index(op.f('ix_jobs_dataset_id'), table_name='jobs')
    op.drop_table('jobs')
    op.drop_index(op.f('ix_datasets_owner_id'), table_name='datasets')
    op.drop_table('datasets')
    # ### end Alembic commands ###
